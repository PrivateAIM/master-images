diff --git a/src/patchcore3d/common.py b/src/patchcore3d/common.py
index e4e35c7..b9251cb 100644
--- a/src/patchcore3d/common.py
+++ b/src/patchcore3d/common.py
@@ -37,5 +37,3 @@ class FaissNN(object):
             # so we can not make a default in the function header.
-            return faiss.index_cpu_to_gpu(
-                faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options()
-            )
+            return faiss.index_cpu_to_gpu(faiss.StandardGpuResources(), 0, index, self._gpu_cloner_options())
         return index
@@ -49,5 +47,3 @@ class FaissNN(object):
         if self.on_gpu:
-            return faiss.GpuIndexFlatL2(
-                faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig()
-            )
+            return faiss.GpuIndexFlatL2(faiss.StandardGpuResources(), dimension, faiss.GpuIndexFlatConfig())
         return faiss.IndexFlatL2(dimension)
@@ -137,5 +133,3 @@ class AverageMerger(_BaseMerger):
         # NxCxWxH -> NxC
-        return features.reshape([features.shape[0], features.shape[1], -1]).mean(
-            axis=-1
-        )
+        return features.reshape([features.shape[0], features.shape[1], -1]).mean(axis=-1)
 
@@ -202,14 +196,9 @@ class RescaleSegmentor:
             _scores = patch_scores.to(self.device)
-            
+
             _scores = _scores.unsqueeze(1)
-            _scores = F.interpolate(
-                _scores, size=self.target_size, mode="trilinear", align_corners=False
-            )
-            _scores = _scores.squeeze(1) 
+            _scores = F.interpolate(_scores, size=self.target_size, mode="trilinear", align_corners=False)
+            _scores = _scores.squeeze(1)
             patch_scores = _scores.cpu().numpy()
 
-        return [
-            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)
-            for patch_score in patch_scores
-        ]
+        return [ndimage.gaussian_filter(patch_score, sigma=self.smoothing) for patch_score in patch_scores]
 
@@ -240,5 +229,3 @@ class NetworkFeatureAggregator(torch.nn.Module):
         for extract_layer in layers_to_extract_from:
-            forward_hook = ForwardHook(
-                self.outputs, extract_layer, layers_to_extract_from[-1]
-            )
+            forward_hook = ForwardHook(self.outputs, extract_layer, layers_to_extract_from[-1])
             if "." in extract_layer:
@@ -255,9 +242,5 @@ class NetworkFeatureAggregator(torch.nn.Module):
             if isinstance(network_layer, torch.nn.Sequential):
-                self.backbone.hook_handles.append(
-                    network_layer[-1].register_forward_hook(forward_hook)
-                )
+                self.backbone.hook_handles.append(network_layer[-1].register_forward_hook(forward_hook))
             else:
-                self.backbone.hook_handles.append(
-                    network_layer.register_forward_hook(forward_hook)
-                )
+                self.backbone.hook_handles.append(network_layer.register_forward_hook(forward_hook))
         self.to(self.device)
@@ -277,5 +260,10 @@ class NetworkFeatureAggregator(torch.nn.Module):
         """Computes the feature dimensions for all layers given input_shape."""
+
+        input_shape = [max(dim, 13) for dim in input_shape]
+
         _input = torch.ones([1, 1] + list(input_shape)).to(self.device)
         _output = self(_input)
-        return [_output[layer].shape[1] for layer in self.layers_to_extract_from], [_output[layer].shape[2:] for layer in self.layers_to_extract_from]
+        return [_output[layer].shape[1] for layer in self.layers_to_extract_from], [
+            _output[layer].shape[2:] for layer in self.layers_to_extract_from
+        ]
 
@@ -286,5 +274,3 @@ class ForwardHook:
         self.layer_name = layer_name
-        self.raise_exception_to_break = copy.deepcopy(
-            layer_name == last_layer_to_extract
-        )
+        self.raise_exception_to_break = copy.deepcopy(layer_name == last_layer_to_extract)
 
@@ -316,5 +302,3 @@ class NearestNeighbourScorer(object):
 
-        self.imagelevel_nn = lambda query: self.nn_method.run(
-            n_nearest_neighbours, query
-        )
+        self.imagelevel_nn = lambda query: self.nn_method.run(n_nearest_neighbours, query)
         self.pixelwise_nn = lambda query, index: self.nn_method.run(1, query, index)
@@ -338,5 +322,3 @@ class NearestNeighbourScorer(object):
 
-    def predict(
-        self, query_features: List[np.ndarray]
-    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:
+    def predict(self, query_features: List[np.ndarray]) -> Union[np.ndarray, np.ndarray, np.ndarray]:
         """Predicts anomaly score.
@@ -390,5 +372,3 @@ class NearestNeighbourScorer(object):
         if save_features_separately:
-            self._save(
-                self._detection_file(save_folder, prepend), self.detection_features
-            )
+            self._save(self._detection_file(save_folder, prepend), self.detection_features)
 
@@ -401,5 +381,3 @@ class NearestNeighbourScorer(object):
         if os.path.exists(self._detection_file(load_folder, prepend)):
-            self.detection_features = self._load(
-                self._detection_file(load_folder, prepend)
-            )
+            self.detection_features = self._load(self._detection_file(load_folder, prepend))
 
@@ -428,6 +406,6 @@ class MahalanobisDistanceScorer(object):
         detection_features = np.array(self.feature_merger.merge(detection_features))
-        
-        print('detection_features', detection_features.shape)
+
+        print("detection_features", detection_features.shape)
         self.mean_mahalanobis = detection_features.mean(axis=0)
-        print('mean', self.mean_mahalanobis.shape)
+        print("mean", self.mean_mahalanobis.shape)
 
@@ -439,7 +417,5 @@ class MahalanobisDistanceScorer(object):
         self.inv_covariance_mahalanobis = np.linalg.inv(cov_mahal)
-        print('inv_covariance_mahalanobis', self.inv_covariance_mahalanobis.shape)
+        print("inv_covariance_mahalanobis", self.inv_covariance_mahalanobis.shape)
 
-    def predict(
-        self, query_features: List[np.ndarray]
-    ) -> Union[np.ndarray, np.ndarray, np.ndarray]:
+    def predict(self, query_features: List[np.ndarray]) -> Union[np.ndarray, np.ndarray, np.ndarray]:
         """Predicts anomaly score.
@@ -459,6 +435,9 @@ class MahalanobisDistanceScorer(object):
 
-        anomaly_scores = ((query_features - self.mean_mahalanobis) @ self.inv_covariance_mahalanobis @ \
-                         (query_features - self.mean_mahalanobis).T).diagonal()
+        anomaly_scores = (
+            (query_features - self.mean_mahalanobis)
+            @ self.inv_covariance_mahalanobis
+            @ (query_features - self.mean_mahalanobis).T
+        ).diagonal()
 
-        return np.array(anomaly_scores), anomaly_scores, anomaly_scores # redundant returns for consistency
+        return np.array(anomaly_scores), anomaly_scores, anomaly_scores  # redundant returns for consistency
 
diff --git a/src/patchcore3d/patchcore3d.py b/src/patchcore3d/patchcore3d.py
index df4fc57..a59d79f 100644
--- a/src/patchcore3d/patchcore3d.py
+++ b/src/patchcore3d/patchcore3d.py
@@ -1,2 +1,3 @@
 """PatchCore and PatchCore detection methods."""
+
 import logging
@@ -15,6 +16,7 @@ from dpipe.im.box import mask2bounding_box
 
-import patchcore3d
-import patchcore3d.backbones
-import patchcore3d.common
-import patchcore3d.sampler
+import PatchCore3D.src.patchcore3d
+import PatchCore3D.src.patchcore3d.backbones
+import PatchCore3D.src.patchcore3d.common
+import PatchCore3D.src.patchcore3d.sampler
+from project_utils import load_image_from_item
 
@@ -23,6 +25,6 @@ LOGGER = logging.getLogger(__name__)
 
-class PatchCore3D(torch.nn.Module):
+class PatchCore3Dc(torch.nn.Module):
     def __init__(self, device):
         """PatchCore anomaly detection class."""
-        super(PatchCore3D, self).__init__()
+        super(PatchCore3Dc, self).__init__()
         self.device = device
@@ -41,4 +43,4 @@ class PatchCore3D(torch.nn.Module):
         anomaly_score_num_nn=1,
-        featuresampler=patchcore3d.sampler.IdentitySampler(),
-        nn_method=patchcore3d.common.FaissNN(False, 4),
+        featuresampler=PatchCore3D.src.patchcore3d.sampler.IdentitySampler(),
+        nn_method=PatchCore3D.src.patchcore3d.common.FaissNN(False, 4),
         target_size_small=(70, 70, 45),
@@ -55,3 +57,3 @@ class PatchCore3D(torch.nn.Module):
 
-        feature_aggregator = patchcore3d.common.NetworkFeatureAggregator(
+        feature_aggregator = PatchCore3D.src.patchcore3d.common.NetworkFeatureAggregator(
             self.backbone, self.layers_to_extract_from, self.device
@@ -63,5 +65,3 @@ class PatchCore3D(torch.nn.Module):
 
-        preprocessing = patchcore3d.common.Preprocessing(
-            feature_dimensions, pretrain_embed_dimension
-        )
+        preprocessing = PatchCore3D.src.patchcore3d.common.Preprocessing(feature_dimensions, pretrain_embed_dimension)
         self.forward_modules["preprocessing"] = preprocessing
@@ -69,5 +69,3 @@ class PatchCore3D(torch.nn.Module):
         self.target_embed_dimension = target_embed_dimension
-        preadapt_aggregator = patchcore3d.common.Aggregator(
-            target_dim=target_embed_dimension
-        )
+        preadapt_aggregator = PatchCore3D.src.patchcore3d.common.Aggregator(target_dim=target_embed_dimension)
 
@@ -77,5 +75,5 @@ class PatchCore3D(torch.nn.Module):
 
-        LOGGER.info(f'Anomaly_scorer_type: {anomaly_scorer_type}')
+        LOGGER.info(f"Anomaly_scorer_type: {anomaly_scorer_type}")
         if anomaly_scorer_type == "NN":
-            self.anomaly_scorer = patchcore3d.common.NearestNeighbourScorer(
+            self.anomaly_scorer = PatchCore3D.src.patchcore3d.common.NearestNeighbourScorer(
                 n_nearest_neighbours=anomaly_score_num_nn, nn_method=nn_method
@@ -83,5 +81,5 @@ class PatchCore3D(torch.nn.Module):
         elif anomaly_scorer_type == "mahalanobis":
-            self.anomaly_scorer = patchcore3d.common.MahalanobisDistanceScorer()
+            self.anomaly_scorer = PatchCore3D.src.patchcore3d.common.MahalanobisDistanceScorer()
 
-        self.anomaly_segmentor = patchcore3d.common.RescaleSegmentor(
+        self.anomaly_segmentor = PatchCore3D.src.patchcore3d.common.RescaleSegmentor(
             device=self.device, target_size=input_shape[-3:]
@@ -89,4 +87,5 @@ class PatchCore3D(torch.nn.Module):
 
-        self.anomaly_segmentor_small = patchcore3d.common.RescaleSegmentor(
-            device=self.device, target_size=target_size_small,
+        self.anomaly_segmentor_small = PatchCore3D.src.patchcore3d.common.RescaleSegmentor(
+            device=self.device,
+            target_size=target_size_small,
         )
@@ -100,3 +99,5 @@ class PatchCore3D(torch.nn.Module):
                 if isinstance(image, dict):
-                    image = image["image"]
+                    image = load_image_from_item(image, to_tensor=True)  # .numpy()
+                    if image is None:
+                        continue
                 with torch.no_grad():
@@ -121,5 +122,3 @@ class PatchCore3D(torch.nn.Module):
 
-        features = [
-            self.patch_maker.patchify(x, return_spatial_info=True) for x in features
-        ]
+        features = [self.patch_maker.patchify(x, return_spatial_info=True) for x in features]
 
@@ -166,4 +165,8 @@ class PatchCore3D(torch.nn.Module):
                     if isinstance(image, dict):
-                        uids.append(image["uid"])
-                        image = image["image"]
+                        uids.append(image["file_name"])
+                        image = load_image_from_item(image, to_tensor=True)  # .numpy()
+                        if image is None:
+                            continue
+                        if min(image.squeeze().shape) <= 12:
+                            continue
                     features.append(_image_to_features(image))
@@ -171,4 +174,4 @@ class PatchCore3D(torch.nn.Module):
                         features = np.concatenate(features, axis=0)
-                        fname = f'{idx + 1}_features.npy'
-                        LOGGER.info(f'Saving features to {fname} (shape: {features.shape})')
+                        fname = f"{idx + 1}_features.npy"
+                        LOGGER.info(f"Saving features to {fname} (shape: {features.shape})")
                         save(features.astype(np.float16), os.path.join(run_save_path, fname))
@@ -176,6 +179,11 @@ class PatchCore3D(torch.nn.Module):
 
-            save_json(uids, os.path.join(run_save_path, 'uids.json'))
-            features = np.vstack([np.load(os.path.join(run_save_path, embedding_file))
-                                  for embedding_file in os.listdir(run_save_path) if embedding_file.endswith('_features.npy')])
-            save(features.astype(np.float16), os.path.join(run_save_path, 'features_1024.npy'))
+            save_json(uids, os.path.join(run_save_path, "uids.json"))
+            features = np.vstack(
+                [
+                    np.load(os.path.join(run_save_path, embedding_file))
+                    for embedding_file in os.listdir(run_save_path)
+                    if embedding_file.endswith("_features.npy")
+                ]
+            )
+            save(features.astype(np.float16), os.path.join(run_save_path, "features_1024.npy"))
             features = features.astype(np.float32)
@@ -183,3 +191,3 @@ class PatchCore3D(torch.nn.Module):
             for embedding_file in os.listdir(run_save_path):
-                if embedding_file.endswith('_features.npy'):
+                if embedding_file.endswith("_features.npy"):
                     os.remove(os.path.join(run_save_path, embedding_file))
@@ -194,5 +202,7 @@ class PatchCore3D(torch.nn.Module):
                 cur_features = self.forward_modules["preprocessing"](
-                    features[i * batch_size: (i + 1) * batch_size][None, ...])
-                new_features[i * batch_size: (
-                    i + 1) * batch_size] = self.forward_modules["preadapt_aggregator"](cur_features)
+                    features[i * batch_size : (i + 1) * batch_size][None, ...]
+                )
+                new_features[i * batch_size : (i + 1) * batch_size] = self.forward_modules["preadapt_aggregator"](
+                    cur_features
+                )
             features = new_features.numpy().astype(np.float32)
@@ -207,4 +217,8 @@ class PatchCore3D(torch.nn.Module):
         if isinstance(data, torch.utils.data.Dataset):
-            return self._predict_dataset(data, saved_test_features_path=saved_test_features_path, 
-                                         run_save_path=run_save_path, save_segmentation_images=save_segmentation_images)
+            return self._predict_dataset(
+                data,
+                saved_test_features_path=saved_test_features_path,
+                run_save_path=run_save_path,
+                save_segmentation_images=save_segmentation_images,
+            )
         return self._predict(data)
@@ -227,10 +241,6 @@ class PatchCore3D(torch.nn.Module):
             save_indices = [0, 1, 1000, 1001, 1002, 1003]
-            image_save_path = os.path.join(
-                run_save_path, "segmentation_images"
-            )
+            image_save_path = os.path.join(run_save_path, "segmentation_images")
             os.makedirs(image_save_path, exist_ok=True)
 
-        pred_save_path = os.path.join(
-            run_save_path, "predictions"
-        )
+        pred_save_path = os.path.join(run_save_path, "predictions")
         os.makedirs(pred_save_path, exist_ok=True)
@@ -246,13 +256,5 @@ class PatchCore3D(torch.nn.Module):
             for idx in data_iterator:
-                
+
                 image = dataset[idx]
                 uid = image["uid"]
-                                
-                is_anomaly = image["is_anomaly"]
-                labels_gt.extend([is_anomaly])
-                mask_gt = image["mask"]
-                small_mask_gt = F.interpolate(
-                    mask_gt.float(), size=self.anomaly_segmentor_small.target_size, mode="trilinear", align_corners=False
-                ) > 0.5
-                small_masks_gt.extend(small_mask_gt.numpy().tolist())
 
@@ -262,5 +264,4 @@ class PatchCore3D(torch.nn.Module):
                     if idx % chunk_size == 0:
-                        chunk_file = f'test_features_{idx}.npy'
-                        chunk_features = load(os.path.join(
-                            saved_test_features_path, chunk_file)).astype(np.float32)
+                        chunk_file = f"test_features_{idx}.npy"
+                        chunk_features = load(os.path.join(saved_test_features_path, chunk_file)).astype(np.float32)
 
@@ -269,7 +270,5 @@ class PatchCore3D(torch.nn.Module):
                         len_chunk = len(chunk_features)
-                        chunk_features = chunk_features.reshape(
-                            -1, chunk_features.shape[-1])
+                        chunk_features = chunk_features.reshape(-1, chunk_features.shape[-1])
 
-                        new_features = np.zeros(
-                            (chunk_features.shape[0], self.target_embed_dimension))
+                        new_features = np.zeros((chunk_features.shape[0], self.target_embed_dimension))
                         new_features = torch.from_numpy(new_features)
@@ -279,4 +278,7 @@ class PatchCore3D(torch.nn.Module):
                             cur_features = self.forward_modules["preprocessing"](
-                                chunk_features[i * batch_size: (i + 1) * batch_size][None, ...])
-                            new_features[i * batch_size: (i + 1) * batch_size] = self.forward_modules["preadapt_aggregator"](cur_features)
+                                chunk_features[i * batch_size : (i + 1) * batch_size][None, ...]
+                            )
+                            new_features[i * batch_size : (i + 1) * batch_size] = self.forward_modules[
+                                "preadapt_aggregator"
+                            ](cur_features)
                         chunk_features = new_features.numpy().astype(np.float32)
@@ -284,4 +286,3 @@ class PatchCore3D(torch.nn.Module):
 
-                        chunk_features = chunk_features.reshape(
-                            (len_chunk, -1, chunk_features.shape[-1]))
+                        chunk_features = chunk_features.reshape((len_chunk, -1, chunk_features.shape[-1]))
 
@@ -290,3 +291,5 @@ class PatchCore3D(torch.nn.Module):
                 else:
-                    image = image["image"]
+                    image = load_image_from_item(image, to_tensor=True)  # .numpy()
+                    if image is None:
+                        continue
                     image_features = None
@@ -294,11 +297,7 @@ class PatchCore3D(torch.nn.Module):
                 _scores, _masks, _small_masks, _anomaly_patches, time_elapsed = self._predict(
-                    image, features=image_features)
+                    image, features=image_features
+                )
                 times.append(time_elapsed)
-                
+
                 segmentations = np.array(_masks)
-                if save_segmentation_images:
-                    if idx in save_indices:
-                        save(segmentations, os.path.join(image_save_path, f'{uid}.npy'))
-                        save(_small_masks[0], os.path.join(image_save_path, f'small_{uid}.npy'))
-                        save(small_mask_gt, os.path.join(image_save_path, f'small_mask_{uid}.npy'))
 
@@ -306,24 +305,20 @@ class PatchCore3D(torch.nn.Module):
                 segmentations = segmentations[None, ...]
-                min_scores = (
-                    segmentations.reshape(len(segmentations), -1)
-                    .min(axis=-1)
-                    .reshape(-1, 1, 1, 1)
-                )
-                max_scores = (
-                    segmentations.reshape(len(segmentations), -1)
-                    .max(axis=-1)
-                    .reshape(-1, 1, 1, 1)
-                )
+                min_scores = segmentations.reshape(len(segmentations), -1).min(axis=-1).reshape(-1, 1, 1, 1)
+                max_scores = segmentations.reshape(len(segmentations), -1).max(axis=-1).reshape(-1, 1, 1, 1)
                 segmentations = (segmentations - min_scores) / (max_scores - min_scores)
                 segmentations = np.mean(segmentations, axis=0)
-                
+
                 _small_masks = np.array(_small_masks)
-                min_ = load('../results_test/ixi_t2/patch3_sp1/data461_sample1_dim128_with_preds/min_scores.npy')[0, 0, 0, 0]
-                max_ = load('../results_test/ixi_t2/patch3_sp1/data461_sample1_dim128_with_preds/max_scores.npy')[0, 0, 0, 0]
-                threshold = 0.006821 * (max_ - min_) + min_
-                if (_small_masks > threshold).sum() == 0:
-                    mask_bbox = None
-                else:
-                    mask_bbox = mask2bounding_box(_small_masks > threshold)
-                mask_bboxes[uid] = mask_bbox
+                # min_ = load("../results_test/ixi_t2/patch3_sp1/data461_sample1_dim128_with_preds/min_scores.npy")[
+                #     0, 0, 0, 0
+                # ]
+                # max_ = load("../results_test/ixi_t2/patch3_sp1/data461_sample1_dim128_with_preds/max_scores.npy")[
+                #     0, 0, 0, 0
+                # ]
+                # threshold = 0.006821 * (max_ - min_) + min_
+                # if (_small_masks > threshold).sum() == 0:
+                #     mask_bbox = None
+                # else:
+                #     mask_bbox = mask2bounding_box(_small_masks > threshold)
+                # mask_bboxes[uid] = mask_bbox
 
@@ -331,21 +326,53 @@ class PatchCore3D(torch.nn.Module):
 
-                if is_anomaly:
-                    pixel_scores = patchcore3d.metrics.compute_pixelwise_retrieval_metrics(
-                        segmentations,
-                        mask_gt.numpy(),
-                    )
-                    single_aucs_dict[uid] = pixel_scores["auroc"]
-                    single_dices_dict[uid] = pixel_scores["dices"][0]
-                    single_slice_dices_dict[uid] = pixel_scores["slice_dices"]
-
                 scores.append(_scores[0])
-                top_anomaly_patches_dict[uid] = (_anomaly_patches[0] * mask_gt.numpy()).sum() > 1e-9
                 small_masks.append(_small_masks[0])
 
-        save(times, os.path.join(run_save_path, 'time.json'))
-        dataset.return_images = True
-        
-        save(mask_bboxes, os.path.join(run_save_path, 'mask_bboxes.json'))
-        
-        return scores, labels_gt, top_anomaly_patches_dict, small_masks, small_masks_gt, single_aucs_dict, single_dices_dict, single_slice_dices_dict
+        save(times, os.path.join(run_save_path, "time.json"))
+        # dataset.return_images = True
+
+        # save(mask_bboxes, os.path.join(run_save_path, "mask_bboxes.json"))
+
+        return (
+            scores,
+            labels_gt,
+            top_anomaly_patches_dict,
+            small_masks,
+            small_masks_gt,
+            single_aucs_dict,
+            single_dices_dict,
+            single_slice_dices_dict,
+        )
+
+    def _predict_simple(self, dataset, run_save_path):
+        """This function provides anomaly scores/maps for full dataloaders."""
+        _ = self.forward_modules.eval()
+
+        scores = []
+
+        for item in dataset:
+
+            try:
+
+                image = load_image_from_item(item, to_tensor=True)  # .numpy()
+                if image is None:
+                    continue
+                image_features = None
+
+                if min(image.squeeze().shape) <= 12:
+                    print("Image too small", item["uid"])
+                    scores.append(0)
+                    continue
+
+                _scores, _masks, _small_masks, _anomaly_patches, time_elapsed = self._predict(
+                    image, features=image_features
+                )
+
+                scores.append(_scores[0])
+
+            except Exception as e:
+                print(e)
+                print("Error with item", item)
+                scores.append(0)
+
+        return scores
 
@@ -368,17 +395,15 @@ class PatchCore3D(torch.nn.Module):
             patch_scores = image_scores = self.anomaly_scorer.predict([features])[0]
-            image_scores = self.patch_maker.unpatch_scores(
-                image_scores, batchsize=batchsize
-            )
+            image_scores = self.patch_maker.unpatch_scores(image_scores, batchsize=batchsize)
 
             image_scores = image_scores.reshape(*image_scores.shape[:2], -1)
-            patch_scores = self.patch_maker.unpatch_scores(
-                patch_scores, batchsize=batchsize
-            )
+            patch_scores = self.patch_maker.unpatch_scores(patch_scores, batchsize=batchsize)
             scales = patch_shapes[0]
-            patch_scores = patch_scores.reshape(
-                batchsize, scales[0], scales[1], scales[2])
+            patch_scores = patch_scores.reshape(batchsize, scales[0], scales[1], scales[2])
 
-            image_scores, highest_anomalies_masks = self.patch_maker.score(image_scores, return_max_mask=True,
-                                                                           patch_scores=patch_scores,
-                                                                           input_shape=self.anomaly_segmentor.target_size)
+            image_scores, highest_anomalies_masks = self.patch_maker.score(
+                image_scores,
+                return_max_mask=True,
+                patch_scores=patch_scores,
+                input_shape=self.anomaly_segmentor.target_size,
+            )
 
@@ -386,6 +411,11 @@ class PatchCore3D(torch.nn.Module):
             time_elapsed = time.time() - start_time
-            small_masks = self.anomaly_segmentor_small.convert_to_segmentation(
-                patch_scores)
-
-        return [sc for sc in image_scores], [m for m in masks], [m for m in small_masks], [an_mask for an_mask in highest_anomalies_masks], time_elapsed
+            small_masks = self.anomaly_segmentor_small.convert_to_segmentation(patch_scores)
+
+        return (
+            [sc for sc in image_scores],
+            [m for m in masks],
+            [m for m in small_masks],
+            [an_mask for an_mask in highest_anomalies_masks],
+            time_elapsed,
+        )
 
@@ -403,6 +433,8 @@ class PatchCore3D(torch.nn.Module):
                 if isinstance(image, dict):
-                    image = image["image"]
+                    image = load_image_from_item(image, to_tensor=True)  # .numpy()
+                    if image is None:
+                        continue
                 features.append(_image_to_features(image))
                 if (idx + 1) % chunk_size == 0 or (idx + 1) == len(input_dataset):
-                    chunk_file = f'test_features_{idx // chunk_size * chunk_size}.npy'
+                    chunk_file = f"test_features_{idx // chunk_size * chunk_size}.npy"
                     # features = np.concatenate(features, axis=0)
@@ -410,3 +442,3 @@ class PatchCore3D(torch.nn.Module):
                     save(features.astype(np.float16), os.path.join(run_save_path, chunk_file))
-                    LOGGER.info('Saving test features with shape {features.shape}')
+                    LOGGER.info("Saving test features with shape {features.shape}")
                     features = []
@@ -419,5 +451,3 @@ class PatchCore3D(torch.nn.Module):
         LOGGER.info("Saving PatchCore data.")
-        self.anomaly_scorer.save(
-            save_path, save_features_separately=False, prepend=prepend
-        )
+        self.anomaly_scorer.save(save_path, save_features_separately=False, prepend=prepend)
         patchcore_params = {
@@ -426,8 +456,4 @@ class PatchCore3D(torch.nn.Module):
             "input_shape": self.input_shape,
-            "pretrain_embed_dimension": self.forward_modules[
-                "preprocessing"
-            ].output_dim,
-            "target_embed_dimension": self.forward_modules[
-                "preadapt_aggregator"
-            ].target_dim,
+            "pretrain_embed_dimension": self.forward_modules["preprocessing"].output_dim,
+            "target_embed_dimension": self.forward_modules["preadapt_aggregator"].target_dim,
             "patchsize": self.patch_maker.patchsize,
@@ -443,3 +469,3 @@ class PatchCore3D(torch.nn.Module):
         device: torch.device,
-        nn_method: patchcore3d.common.FaissNN(False, 4),
+        nn_method: PatchCore3D.src.patchcore3d.common.FaissNN(False, 4),
         prepend: str = "",
@@ -449,3 +475,3 @@ class PatchCore3D(torch.nn.Module):
             patchcore_params = pickle.load(load_file)
-        patchcore_params["backbone"] = patchcore3d.backbones.load(device)
+        patchcore_params["backbone"] = PatchCore3D.src.patchcore3d.backbones.load(device)
         patchcore_params["backbone"].name = patchcore_params["backbone.name"]
@@ -483,5 +509,3 @@ class PatchMaker3D:
         for s in features.shape[-3:]:
-            n_patches = (
-                s + 2 * padding - 1 * (self.patchsize - 1) - 1
-            ) / self.stride + 1
+            n_patches = (s + 2 * padding - 1 * (self.patchsize - 1) - 1) / self.stride + 1
             number_of_total_patches.append(int(n_patches))
@@ -505,5 +529,5 @@ class PatchMaker3D:
     ) -> torch.Tensor:
-        ''' 
-        Function to perform unfolding of a 5D tensor (not implemented in pytorch) 
-        '''
+        """
+        Function to perform unfolding of a 5D tensor (not implemented in pytorch)
+        """
 
@@ -520,5 +544,3 @@ class PatchMaker3D:
 
-        def _get_im2col_indices_along_dim(
-            input_d, kernel_d, dilation_d, padding_d, stride_d
-        ):
+        def _get_im2col_indices_along_dim(input_d, kernel_d, dilation_d, padding_d, stride_d):
             blocks_d = input_d + padding_d * 2 - dilation_d * (kernel_d - 1)
@@ -526,5 +548,3 @@ class PatchMaker3D:
             # Stride kernel over input and find starting indices along dim d
-            blocks_d_indices = torch.arange(
-                0, blocks_d, stride_d, dtype=torch.int64, device=input.device
-            ).unsqueeze(0)
+            blocks_d_indices = torch.arange(0, blocks_d, stride_d, dtype=torch.int64, device=input.device).unsqueeze(0)
             num_blocks = (blocks_d - 1) // stride_d + 1
@@ -552,14 +572,10 @@ class PatchMaker3D:
 
-        padded_input = F.pad(input, (padding_d, padding_d,
-                             padding_w, padding_w, padding_h, padding_h))
+        padded_input = F.pad(input, (padding_d, padding_d, padding_w, padding_w, padding_h, padding_h))
 
-        blocks_row_indices = blocks_row_indices.unsqueeze(
-            -1).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)
+        blocks_row_indices = blocks_row_indices.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)
         blocks_col_indices = blocks_col_indices.unsqueeze(-1).unsqueeze(-1)
-        output = padded_input[:, :, blocks_row_indices,
-                              blocks_col_indices, blocks_depth_indices]
+        output = padded_input[:, :, blocks_row_indices, blocks_col_indices, blocks_depth_indices]
         output = output.permute(0, 1, 2, 4, 6, 3, 5, 7)
         return output.reshape(
-            batch_dim, channel_dim * kernel_h * kernel_w *
-            kernel_d, num_blocks_row * num_blocks_col * num_blocks_depth
+            batch_dim, channel_dim * kernel_h * kernel_w * kernel_d, num_blocks_row * num_blocks_col * num_blocks_depth
         )
@@ -583,10 +599,13 @@ class PatchMaker3D:
         if return_max_mask:
-            flat_indices = torch.stack([torch.argmax(patch_scores[ind])
-                                       for ind in range(patch_scores.shape[0])])
-
-            one_hot_mask.reshape(
-                one_hot_mask.shape[0], -1)[range(one_hot_mask.shape[0]), flat_indices] = 1
-            one_hot_mask = torch.stack([F.interpolate(one_hot_mask[ind][None, None, ...],
-                                                      size=input_shape, mode="trilinear", align_corners=False)
-                                        for ind in range(one_hot_mask.shape[0])])[:, 0, 0]
+            flat_indices = torch.stack([torch.argmax(patch_scores[ind]) for ind in range(patch_scores.shape[0])])
+
+            one_hot_mask.reshape(one_hot_mask.shape[0], -1)[range(one_hot_mask.shape[0]), flat_indices] = 1
+            one_hot_mask = torch.stack(
+                [
+                    F.interpolate(
+                        one_hot_mask[ind][None, None, ...], size=input_shape, mode="trilinear", align_corners=False
+                    )
+                    for ind in range(one_hot_mask.shape[0])
+                ]
+            )[:, 0, 0]
             one_hot_mask = one_hot_mask.bool()
